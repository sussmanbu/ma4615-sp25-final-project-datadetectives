---
title: "Boom, Bust and Balance - Between The Lines of Income and Interest Rates"
description: "Exploring the 2008 Crisis ."
toc: true
draft: FALSE
filters:
  - shinylive
---

![](images/bigpic-tightrope.png)

This comes from the file `big_picture.qmd`.

### Introduction
Picture this — you’re approaching a major crossroads in life. Maybe you’re saving for retirement, helping your kids through college, or finally feeling financially secure after decades of hard work. Then, almost overnight, the economy crumbles. Home values plummet, jobs vanish, and uncertainty becomes the new normal.

This was the reality for members of the 1979 National Longitudinal Survey of Youth cohort, who found themselves navigating one of the most severe economic downturns in modern history right at a critical point in their financial lives.

How did the Great Recession of 2008 impact their incomes? How did falling interest rates shape their financial decisions and opportunities?
In the analysis ahead, we dive into these questions — using regression models to uncover how income and interest rate dynamics shifted from 2006 to 2010. Join us as we explore the lasting financial ripples of the crisis and the stories hidden within the numbers.


---


### Interactive

Your Big Data page should also include a small interactive dashboard. The dashboard should be created either using Shinylive, as below. This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.

```{r shinymap, echo= FALSE, message=FALSE}
library(shiny)
library(tidyverse)
library(leaflet)
library(geojsonio)
library(shinydashboard)
library(sf)

# Load data
nls_data_clean <- read_csv("dataset/nls_clean.csv")
interest_rates_cleaned <- read_csv("dataset/interest_rates_cleaned.csv")

# Load US states GeoJSON
us_states <- geojson_read(
  "https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json",
  what = "sp"
)

# Create region lookup
region_lookup <- tibble(
  state = tolower(c("maine", "new hampshire", "vermont", "massachusetts", 
                    "rhode island", "connecticut", "new york", "new jersey",
                    "pennsylvania", "ohio", "indiana", "illinois", "michigan",
                    "wisconsin", "minnesota", "iowa", "missouri", "north dakota",
                    "south dakota", "nebraska", "kansas", "delaware", "maryland",
                    "virginia", "west virginia", "north carolina", "south carolina",
                    "georgia", "florida", "kentucky", "tennessee", "alabama",
                    "mississippi", "arkansas", "louisiana", "oklahoma", "texas",
                    "montana", "wyoming", "colorado", "new mexico", "idaho",
                    "utah", "arizona", "washington", "oregon", "nevada",
                    "california", "alaska", "hawaii")),
  region = case_when(
    state %in% tolower(c("maine", "new hampshire", "vermont", "massachusetts", 
                         "rhode island", "connecticut", "new york", 
                         "new jersey", "pennsylvania")) ~ "North East",
    state %in% tolower(c("ohio", "indiana", "illinois", "michigan", "wisconsin",
                         "minnesota", "iowa", "missouri", "north dakota",
                         "south dakota", "nebraska", "kansas")) ~ "Central",
    state %in% tolower(c("delaware", "maryland", "virginia", "west virginia",
                         "north carolina", "south carolina", "georgia",
                         "florida", "kentucky", "tennessee", "alabama",
                         "mississippi", "arkansas", "louisiana", "oklahoma",
                         "texas")) ~ "South",
    TRUE ~ "West"
  )
)

# Map state names to region
state_to_region <- region_lookup$region
names(state_to_region) <- region_lookup$state

# Add region info to us_states
us_states@data$region <- state_to_region[tolower(us_states@data$name)]

# Remove NA regions
us_states <- us_states[!is.na(us_states@data$region), ]

# Convert to sf
us_states_sf <- st_as_sf(us_states)

# Add region info
us_states_sf$region <- state_to_region[tolower(us_states_sf$name)]

# Remove states we can't cleanly merge (Alaska + Hawaii for now)
us_states_sf <- us_states_sf %>%
  filter(!name %in% c("Alaska", "Hawaii"))

# Fix geometries
us_states_sf <- st_make_valid(us_states_sf)

# Merge states into regions
regions_sf <- us_states_sf %>%
  group_by(region) %>%
  summarize(geometry = st_union(geometry), .groups = "drop")


# --- UI ---
ui <- fluidPage(
  titlePanel("Recession Impact Map (Regions)"),
  sidebarLayout(
    sidebarPanel(
      radioButtons("filter", "Filter Result Cards By:",
                   choices = c("Income by year"),  # no interest rate anymore
                   selected = "Income by year")
    ),
    mainPanel(
      leafletOutput("map", height = 600),
      fluidRow(
        valueBoxOutput("card2006"),
        valueBoxOutput("card2008"),
        valueBoxOutput("card2010")
      )
    )
  )
)

# --- Server ---
server <- function(input, output, session) {
  
  selected_region <- reactiveVal(NULL)
  
  get_mean_value <- function(year, type) {
  region_name <- selected_region()
  
  if (type == "Income by year") {
    if (is.null(region_name)) {
      # If no region clicked, return overall national average income
      nls_data_clean %>%
        pull(paste0("Income_", year)) %>%
        mean(na.rm = TRUE)
    } else {
      # If region clicked, return average for that region
      nls_data_clean %>%
        filter(Region == region_name) %>%
        pull(paste0("Income_", year)) %>%
        mean(na.rm = TRUE)
    }
  }
}

  
  output$map <- renderLeaflet({
    leaflet(regions_sf) %>%
      addTiles() %>%
      addPolygons(
        fillColor = ~case_when(
          region == "North East" ~ "#1f77b4",
          region == "Central" ~ "#2ca02c",
          region == "South" ~ "#ff7f0e",
          region == "West" ~ "#d62728",
          TRUE ~ "gray"
        ),
        fillOpacity = 0.7,
        color = "white",
        weight = 1,
        label = ~region,
        layerId = ~region,
        highlightOptions = highlightOptions(
          weight = 5,
          color = "black",
          bringToFront = TRUE
        )
      )
  })

  observeEvent(input$map_shape_click, {
    click_region <- input$map_shape_click$id
    if (!is.null(click_region)) {
      data_region <- case_when(
        click_region == "North East" ~ "Northeast",
        click_region == "Central" ~ "North Central",
        TRUE ~ click_region  # South and West match exactly
      )
      selected_region(data_region)
    }
  })
  
  
  output$card2006 <- renderValueBox({
    value <- scales::dollar(round(get_mean_value(2006, input$filter)))
    
    region_display <- if (is.null(selected_region())) {
  "National Average"
} else {
  selected_region()
}

subtitle <- paste("Income 2006 -", region_display)
    valueBox(value, subtitle, color = "blue")
  })
  
  output$card2008 <- renderValueBox({
    value <- scales::dollar(round(get_mean_value(2008, input$filter)))
    region_display <- if (is.null(selected_region())) {
  "National Average"
} else {
  selected_region()
}

subtitle <- paste("Income 2006 -", region_display)
    valueBox(value, subtitle, color = "green")
  })
  
  output$card2010 <- renderValueBox({
    value <- scales::dollar(round(get_mean_value(2010, input$filter)))
    region_display <- if (is.null(selected_region())) {
  "National Average"
} else {
  selected_region()
}

subtitle <- paste("Income 2006 -", region_display)
    valueBox(value, subtitle, color = "red")
  })
}

# Run the app
shinyApp(ui, server)

```


```{r, echo= FALSE, message=FALSE}
#| eval: false
#| standalone: true
#| viewerHeight: 640 # You will have to adjust this to fit everything


library(shiny)
library(tidyverse)
options("readr.edition" = 1) # keep this to ensure you can download the data


# Define UI for app that draws a histogram ----
ui <- fluidPage(

  # App title ----
  titlePanel("Hello Shiny!"),

  # Sidebar layout with input and output definitions ----
  verticalLayout(
      # Input: Slider for the number of bins ----
      sliderInput(inputId = "bins",
                  label = "Number of bins:",
                  min = 1,
                  max = 50,
                  value = 30),

      # Output: Histogram ----
      plotOutput(outputId = "distPlot")

  )
)

# Define server logic required to draw a histogram ----
server <- function(input, output) {
  # The URL below has to point to a dataset on your github pages website
  # I recommend creating a small-ish rds file that has only the data relevant to 
  # the interactive.
  data <- read_rds("https://sussmanbu.github.io/ma4615-final-project-quarto/dataset_for_shiny/combined_regional_data.rds")
  
  output$distPlot <- renderPlot({
    ggplot(data, aes(x = refusal_rate)) +
      geom_histogram(bins = input$bins + 1)

  })

}

# Create Shiny app ----
shinyApp(ui = ui, server = server)
```

To get the shinylive-r working.
 
1. Make sure your shiny app works as a regular r chunk.
2. Make sure that the chunk is completely self-contained. Meaning all packages and data are loaded inside that chunk. It can't rely on any other chunks.
3. For the data that you are using for shiny, copy the rds file or any other files into the scripts folder, and then publish your website.
4. Where you load in your data, change it to use a URL to the data set which will now be on your website. Something like read_rds("https://sussmanbu.github.io/ma-4615-fa24-final-project-group-a/scripts/dataset_for_shiny.rds")
5. Check that the chunk still works as a regular r chunk.
6. Change it to a shinylive-r chunk.
7. Commit and publish your work.

I recommend keeping the data used for the shiny interactive relatively small, though this isn't completely necessary.

---




## Rubric: On this page


* Title
  * Your big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.
* Clarity of Explanation
  * You should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don't go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.
  * Each figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.
* Creativity
  * Do your best to make things interesting. Think of a how a news article or a magazine story might draw you in. Think of how each part of your analysis supports the previous part or provides a different perspective.
* Interactive component
  * Quality and ease of use of the interactive components.
Is it clear what can be explored using your interactive components?
Does it enhance and reinforce your conclusions?
* This page should be self-contained.
  
**Note**: This page should have no code visible, i.e. use `#| echo: FALSE`.  




## Rubric: Other components

### Video Recording

Make a video recording (probably using Zoom) demonstrating your interactive components.
You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA.
This video should be no longer than 4 minutes.
Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website.
This can be presented by any subset of the team members.


### Rest of the Site

Finally, here are important things to keep in mind for the rest of the site. 

The main title of your page is informative.
Each post has an author/description/informative title.
All lab required posts are present.
Each page (including the home page) has a nice featured image associated with it.
Your about page is up to date and clean.
You have removed the generic posts from the initial site template.
